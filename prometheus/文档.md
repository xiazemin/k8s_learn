server端从被监控主机获取数据，而agent端需要部署一个node_exporter，主要用于数据采集和暴露节点的数据，那么 在获取Pod级别或者是mysql等多种应用的数据，也是需要部署相关的exporter。我们可以通过PromQL的方式对数据进行查询，但是由于本身prometheus属于第三方的 解决方案，原生的k8s系统并不能对Prometheus的自定义指标进行解析，就需要借助于k8s-prometheus-adapter将这些指标数据查询接口转换为标准的Kubernetes自定义指标。


每个被监控的主机都可以通过专用的exporter程序提供输出监控数据的接口，并等待Prometheus服务器周期性的进行数据抓取。
如果存在告警规则，则抓取到数据之后会根据规则进行计算，满足告警条件则会生成告警，并发送到Alertmanager完成告警的汇总和分发。
当被监控的目标有主动推送数据的需求时，可以以Pushgateway组件进行接收并临时存储数据，然后等待Prometheus服务器完成数据的采集。

https://www.cnblogs.com/linuxk/p/10582534.html



文件清单：
node-exporter：prometheus的export，收集Node级别的监控数据
prometheus：监控服务端，从node-exporter拉数据并存储为时序数据。
kube-state-metrics：能够采集绝大多数k8s内置资源的相关数据，例如pod、deploy状态等等。同时它也提供自己的数据，主要是资源采集个数和采集发生的异常次数统计
k8s-prometheus-adpater：聚合进apiserver，即一种custom-metrics-apiserver实现
开启Kubernetes aggregator功能（参考上文metric-server）

原生的k8s系统并不能对Prometheus的自定义指标进行解析，就需要借助于k8s-prometheus-adapter将这些指标数据查询接口转换为标准的Kubernetes自定义指标。

https://www.cnblogs.com/centos-python/articles/10921991.html


任何被监控的目标都需要事先纳入到监控系统中才能进行时序数据采集、存储、告警及相关的展示等等，监控目标既可以通过配置信息以静态形式指定，也可以让Prometheus通过服务发现机制动态管理（增删等等），对于变动频繁的系统环境（如容器云环境）来说，这种动态管理机制尤为有用。在Kubernetes集群及相关的环境中，除了此前配置的从Pod对象中的容器应用获得资源指标数据以外，Promethues还支持通过多个监控目标采集Kubernetes监控架构中所谓的"非核心指标数据"。
　　1）监控代理程序，如node_exporter，收集标准的主机指标数据，包括平均负载、CPU、Memory、Disk、Network及诸多其他维度的数据，独立的指标可能多达上千个。
　　2）kubelet（cAdvisor）：收集容器指标数据，它们也是所谓的Kubernetes"核心指标"，每个容器的相关指标数据主要有CPU利用率（user和system）及限额、文件系统读/写限额、内存利用率及限额、网络报文发送/接收/丢弃速率等等。
　　3）API Server：收集API Server的性能指标数据，包括控制工作队列的性能、请求速率与延迟时长、etcd缓存工作队列及缓存性能、普通进程状态（文件描述符、内存、CPU等等）、Golang状态（GC、内存和线程等等）。
　　4）etcd：收集存储集群的相关指标数据，包括领导节点及领域变动速率、提交/应用/挂起/错误的提案次数、磁盘写入性能、网络与gRPC计数器等等。
　　5）kube-state-metrics：此组件能够派生出Kubernetes相关的多个指标数据，主要是资源类型相关的计数器和元数据信息，包括指定类型的对象总数、资源限额、容器状态（ready/restart/running/terminared/waiting）以及Pod资源的标签系列等等。
　　Prometheus能够直接把Kubernetes API Server作为服务发现系统使用进而动态发现和监控集群中的所有可被监控的对象。这里需要特别说明的是，Pod资源需要添加如下注解信息才能被Prometheus系统自动发现并抓取其内建的指标数据。
　　1）prometheus.io/scrape：用于标识是否需要被采集指标数据，布尔型值，true或false。
　　2）prometheus.io/path：抓取指标数据时使用的URL路径，一般为/metrics。
　　3）prometheus.io/port：抓取指标数据时使用的套接字端口，如8080。
　　另外，仅期望Prometheus为后端生成自定义指标时仅部署Prometheus服务器即可，它甚至也不需要数据持久功能。但若要配置完整功能的监控系统，管理员还需要在每个主机上部署node_exporter、按需部署其他特有的类型的exporter以及Altermanager。



k8s监控方案
cadvisor+heapster+influxdb+grafana
缺点：只能支持监控容器资源，无法支持业务监控，扩展性较差

cadvisor/exporter+prometheus+grafana
总体流程: 数据采集-->汇总-->处理-->存储-->展示

https://www.jianshu.com/p/e76053b6f3f5

https://blog.51cto.com/newfly/2061135
https://www.jianshu.com/p/f5da3d0fd376


Prometheus作为一个核心的控制器，它会创建Prometheus(Prometheus Server)、ServiceMonitor（exporter抽象）、AlertManager、prometheus-rule(prometheus的监控规则)这四个资源(CRD)对象，operator会一直监控并维持这四个资源对象的状态。监控prometheus不需要每个服务单独创建修改规则而是通过直接管理Operator来进行集群的监控。
https://zhuanlan.zhihu.com/p/357331338


在Rancher 2.5中，我们引入了基于Prometheus Operator的新版监控，它可以提供Prometheus以及相关监控组件的原生Kubernetes部署和管理。Prometheus Operator可以让你监控集群节点、Kubernetes组件和应用程序工作负载的状态和进程。同时，它还能够通过Prometheus收集的指标来定义告警并且创建自定义仪表盘，通过Grafana可以轻松地可视化收集到的指标。你可以访问下列链接获取更多关于新版监控组件的细节：

https://rancher.com/docs/rancher/v2.x/en/monitoring-alerting/v2.5/

部署ServiceMonitor
ServiceMonitor是一个自定义资源定义（CRD），可以让我们声明性地定义如何监控一组动态服务。

你可以访问以下链接查看完整的ServiceMonitor规范：

https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#servicemonitor

现在，我们来部署ServiceMonitor，Prometheus用它来收集组成prometheus-example-app Kubernetes服务的pod。

https://www.jianshu.com/p/4fa73569aac7
